{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Sentiment Pipeline: Demonstration\n",
    "\n",
    "This notebook demonstrates the multi-model inference pipeline that chains:\n",
    "1. **Image Captioning** (BLIP model)\n",
    "2. **Sentiment Analysis** (DistilBERT model)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Problem**: Modern ML applications often require multiple models working together. This project explores how to:\n",
    "- Chain models effectively\n",
    "- Handle error propagation\n",
    "- Deploy composite AI systems\n",
    "- Measure end-to-end performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install transformers torch pillow requests matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from image_captioner import ImageCaptioner\n",
    "from sentiment_analyzer import SentimentAnalyzer\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Image Captioning Model...\")\n",
    "captioner = ImageCaptioner(model_name=\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "print(\"\\nLoading Sentiment Analysis Model...\")\n",
    "sentiment_analyzer = SentimentAnalyzer(model_name=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "print(\"\\n‚úÖ All models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Demo - Single Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_display(image_path):\n",
    "    \"\"\"\n",
    "    Analyze an image through the full pipeline and display results\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Generate caption\n",
    "    print(\"Generating caption...\")\n",
    "    start = time.time()\n",
    "    caption = captioner.generate_caption(image)\n",
    "    caption_time = time.time() - start\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    start = time.time()\n",
    "    sentiment_result = sentiment_analyzer.analyze_sentiment(caption)\n",
    "    sentiment_time = time.time() - start\n",
    "    \n",
    "    # Display results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Show image\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Input Image', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Show results\n",
    "    ax2.axis('off')\n",
    "    results_text = f\"\"\"\n",
    "    ANALYSIS RESULTS\n",
    "    {'='*50}\n",
    "    \n",
    "    üìù Caption:\n",
    "    \\\"{caption}\\\"\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    üòä Sentiment: {sentiment_result['label']}\n",
    "    üìä Confidence: {sentiment_result['score']:.2%}\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    ‚è±Ô∏è  Performance:\n",
    "    ‚Ä¢ Caption Time: {caption_time*1000:.1f}ms\n",
    "    ‚Ä¢ Sentiment Time: {sentiment_time*1000:.1f}ms\n",
    "    ‚Ä¢ Total Time: {(caption_time + sentiment_time)*1000:.1f}ms\n",
    "    \"\"\"\n",
    "    \n",
    "    ax2.text(0.1, 0.5, results_text, \n",
    "             fontsize=12, \n",
    "             verticalalignment='center',\n",
    "             fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'caption': caption,\n",
    "        'sentiment': sentiment_result['label'],\n",
    "        'confidence': sentiment_result['score'],\n",
    "        'caption_time': caption_time,\n",
    "        'sentiment_time': sentiment_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze an image\n",
    "# Replace with your own image path\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "\n",
    "# If you don't have an image, we'll create a sample one\n",
    "if not Path(image_path).exists():\n",
    "    print(\"Creating a sample image for demonstration...\")\n",
    "    from PIL import ImageDraw\n",
    "    \n",
    "    sample_img = Image.new('RGB', (400, 300), color=(135, 206, 235))  # Sky blue\n",
    "    draw = ImageDraw.Draw(sample_img)\n",
    "    \n",
    "    # Draw a simple sun\n",
    "    draw.ellipse([50, 50, 150, 150], fill='yellow', outline='orange')\n",
    "    \n",
    "    # Draw text\n",
    "    draw.text((160, 130), \"Sample Image\", fill='white')\n",
    "    \n",
    "    sample_img.save('sample_demo.jpg')\n",
    "    image_path = 'sample_demo.jpg'\n",
    "\n",
    "result = analyze_and_display(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Batch Analysis\n",
    "\n",
    "Analyze multiple images to understand performance patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze(image_paths):\n",
    "    \"\"\"\n",
    "    Analyze multiple images and return aggregate statistics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths, 1):\n",
    "        print(f\"\\nProcessing image {i}/{len(image_paths)}: {img_path}\")\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Caption\n",
    "            start = time.time()\n",
    "            caption = captioner.generate_caption(image)\n",
    "            caption_time = time.time() - start\n",
    "            \n",
    "            # Sentiment\n",
    "            start = time.time()\n",
    "            sentiment_result = sentiment_analyzer.analyze_sentiment(caption)\n",
    "            sentiment_time = time.time() - start\n",
    "            \n",
    "            results.append({\n",
    "                'image': img_path,\n",
    "                'caption': caption,\n",
    "                'sentiment': sentiment_result['label'],\n",
    "                'confidence': sentiment_result['score'],\n",
    "                'caption_time': caption_time,\n",
    "                'sentiment_time': sentiment_time,\n",
    "                'total_time': caption_time + sentiment_time\n",
    "            })\n",
    "            \n",
    "            print(f\"  Caption: {caption}\")\n",
    "            print(f\"  Sentiment: {sentiment_result['label']} ({sentiment_result['score']:.2%})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample images for batch processing\n",
    "from PIL import ImageDraw\n",
    "\n",
    "sample_images = []\n",
    "colors = [(255, 200, 200), (200, 255, 200), (200, 200, 255), (255, 255, 200), (255, 200, 255)]\n",
    "labels = ['Sunset', 'Forest', 'Ocean', 'Desert', 'Mountain']\n",
    "\n",
    "for i, (color, label) in enumerate(zip(colors, labels)):\n",
    "    img = Image.new('RGB', (300, 200), color=color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((100, 90), label, fill='black')\n",
    "    \n",
    "    filename = f'sample_{i+1}.jpg'\n",
    "    img.save(filename)\n",
    "    sample_images.append(filename)\n",
    "\n",
    "# Run batch analysis\n",
    "batch_results = batch_analyze(sample_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timing data\n",
    "caption_times = [r['caption_time'] * 1000 for r in batch_results]  # Convert to ms\n",
    "sentiment_times = [r['sentiment_time'] * 1000 for r in batch_results]\n",
    "total_times = [r['total_time'] * 1000 for r in batch_results]\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Timing breakdown\n",
    "ax = axes[0, 0]\n",
    "x = np.arange(len(batch_results))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, caption_times, width, label='Caption', alpha=0.8)\n",
    "ax.bar(x + width/2, sentiment_times, width, label='Sentiment', alpha=0.8)\n",
    "ax.set_xlabel('Image Index')\n",
    "ax.set_ylabel('Time (ms)')\n",
    "ax.set_title('Processing Time Breakdown by Component')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Total latency distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(total_times, bins=10, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.mean(total_times), color='red', linestyle='--', label=f'Mean: {np.mean(total_times):.1f}ms')\n",
    "ax.set_xlabel('Total Latency (ms)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('End-to-End Latency Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Sentiment distribution\n",
    "ax = axes[1, 0]\n",
    "sentiments = [r['sentiment'] for r in batch_results]\n",
    "sentiment_counts = {s: sentiments.count(s) for s in set(sentiments)}\n",
    "ax.bar(sentiment_counts.keys(), sentiment_counts.values(), alpha=0.7)\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Sentiment Distribution Across Images')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Confidence distribution\n",
    "ax = axes[1, 1]\n",
    "confidences = [r['confidence'] for r in batch_results]\n",
    "ax.hist(confidences, bins=10, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.mean(confidences), color='red', linestyle='--', label=f'Mean: {np.mean(confidences):.2%}')\n",
    "ax.set_xlabel('Confidence Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Sentiment Confidence Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of images analyzed: {len(batch_results)}\")\n",
    "print(f\"\\nLatency Statistics (ms):\")\n",
    "print(f\"  Caption - Mean: {np.mean(caption_times):.1f}, Median: {np.median(caption_times):.1f}\")\n",
    "print(f\"  Sentiment - Mean: {np.mean(sentiment_times):.1f}, Median: {np.median(sentiment_times):.1f}\")\n",
    "print(f\"  Total - Mean: {np.mean(total_times):.1f}, Median: {np.median(total_times):.1f}\")\n",
    "print(f\"  P95 Latency: {np.percentile(total_times, 95):.1f}ms\")\n",
    "print(f\"  P99 Latency: {np.percentile(total_times, 99):.1f}ms\")\n",
    "print(f\"\\nCaption Time as % of Total: {np.mean(caption_times)/np.mean(total_times)*100:.1f}%\")\n",
    "print(f\"Average Confidence: {np.mean(confidences):.2%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Error Propagation Analysis\n",
    "\n",
    "How do errors in caption generation affect downstream sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple captions for the same image to see variation\n",
    "test_image = Image.open(sample_images[0])\n",
    "\n",
    "print(\"Generating multiple captions for error analysis...\\n\")\n",
    "captions = captioner.generate_multiple_captions(test_image, num_captions=5)\n",
    "\n",
    "print(\"Caption Variations and Their Sentiments:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    sentiment_result = sentiment_analyzer.analyze_sentiment(caption)\n",
    "    print(f\"\\n{i}. Caption: \\\"{caption}\\\"\")\n",
    "    print(f\"   Sentiment: {sentiment_result['label']} (confidence: {sentiment_result['score']:.2%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Observation: Minor variations in captions can lead to different\")\n",
    "print(\"sentiment predictions, demonstrating error propagation in the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: API Testing (if server is running)\n",
    "\n",
    "Test the deployed API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def test_api(image_path, base_url=\"http://localhost:8000\"):\n",
    "    \"\"\"\n",
    "    Test the deployed API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Health check\n",
    "        health = requests.get(f\"{base_url}/health\", timeout=5)\n",
    "        print(f\"API Health: {health.json()['status']}\")\n",
    "        \n",
    "        # Analyze image\n",
    "        with open(image_path, 'rb') as f:\n",
    "            files = {'file': f}\n",
    "            response = requests.post(f\"{base_url}/analyze-image\", files=files, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"\\nAPI Response:\")\n",
    "            print(f\"  Caption: {result['caption']}\")\n",
    "            print(f\"  Sentiment: {result['sentiment']}\")\n",
    "            print(f\"  Confidence: {result['sentiment_confidence']:.2%}\")\n",
    "            print(f\"  Processing Time: {result['processing_time_ms']:.1f}ms\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå API server not running. Start it with: python src/server.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Test the API\n",
    "print(\"Testing API endpoint...\\n\")\n",
    "api_result = test_api(sample_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Chaining Works**: Successfully implemented a pipeline where image captions flow into sentiment analysis\n",
    "\n",
    "2. **Performance Bottleneck**: Image captioning accounts for ~80-90% of total processing time\n",
    "\n",
    "3. **Error Propagation**: Variations in caption generation can affect sentiment predictions\n",
    "\n",
    "4. **Latency**: End-to-end latency suitable for near-real-time applications (~500-700ms on CPU)\n",
    "\n",
    "### Future Improvements:\n",
    "\n",
    "- Implement model caching to reduce latency\n",
    "- Add batch processing for multiple images\n",
    "- Fine-tune models on domain-specific data\n",
    "- Implement async processing for better throughput\n",
    "- Add more sophisticated error handling in the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
